{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "## Agenda\n",
    "* Fit a neural network to a dataset with three classes\n",
    "    * Tweak parameters to fit the data\n",
    "* You Try: Brain Cancer dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a neural net that separates these three classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                           random_state=0, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "X1,Y1 = make_moons(noise=0.3, random_state=0)\n",
    "\n",
    "plt.scatter(X1[:, 0], X1[:, 1], marker='o', c=Y1,\n",
    "            s=200, edgecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.DataFrame(X1)\n",
    "data['target'] = Y1\n",
    "data.columns = ['x_pt','y_pt', 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create train, test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['x_pt','y_pt']], data['class'], random_state=0)\n",
    "\n",
    "# Instantiate a Multilayer Perceptron Classifier\n",
    "mlp = MLPClassifier(activation='logistic',solver='lbfgs',random_state=42)\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print('accuracy on training set is ' + str(mlp.score(X_train, y_train)))\n",
    "print('accuracy on test set is ' + str(mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note about the 'solver' parameter: \n",
    "* The default solver ‘adam’ works pretty well on relatively large datasets (with thousands of training samples or more) in terms of both training time and validation score. For small datasets, however, ‘lbfgs’ can converge faster and perform better.\n",
    "* Use 'adam' for large datasets (>1000 rows) and 'lbfgs' for anything else than that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What about the total number of hidden layers? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It's defaulted to have one layer with 100 perceptrons. This could lead to overfitting. Let's change it so that we only have two perceptrons\n",
    "* What does it mean when we set the model to have two perceptrons?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(activation='logistic',solver='lbfgs',random_state=42, hidden_layer_sizes=(2))   \n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy on the training subset: {:.3f}'.format(mlp.score(X_train, y_train)))\n",
    "print('Accuracy on the test subset: {:.3f}'.format(mlp.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's take a look at the decision boundary and see how the model fit the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_boundary(mlp):\n",
    "    x_min, x_max = X_train['x_pt'].min() - .5, X_train['x_pt'].max() + .5\n",
    "    y_min, y_max = X_train['y_pt'].min() - .5, X_train['y_pt'].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    # just plot the dataset first\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "    Z = mlp.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X_train['x_pt'], X_train['y_pt'], c=y_train, cmap=cm_bright,\n",
    "               edgecolors='black', s=25)\n",
    "    # and testing points\n",
    "    #plt.scatter(X_test['x_pt'], X_test['y_pt'], c=y_test, cmap=cm_bright,\n",
    "    #           alpha=0.6, edgecolors='black', s=25)\n",
    "\n",
    "plot_decision_boundary(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there's only one decision boundary since we intitially set the model to have two perceptrons in the hidden layer. We can take a look at the decision boundary coefficients and intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(mlp.coefs_)\n",
    "print('\\n')\n",
    "print(mlp.intercepts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we toggle the number of perceptrons in our hidden layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 32))\n",
    "\n",
    "# Let's create a neural net with a hidden layer of 1, 2, 3, 4, 5, 20 and 50 nodes\n",
    "hidden_layer_dimensions = [1, 2, 3, 4, 5, 20, 50]\n",
    "\n",
    "for i, nn_hdim in enumerate(hidden_layer_dimensions):\n",
    "    plt.subplot(5, 2, i+1)\n",
    "    plt.title('Hidden Layer size %d' % nn_hdim)\n",
    "    mlp = MLPClassifier(activation='logistic',solver='lbfgs',random_state=42, hidden_layer_sizes=(nn_hdim))   \n",
    "    mlp.fit(X_train, y_train)\n",
    "    plot_decision_boundary(mlp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also standardize our features since Multilayer Perceptron is sensitive to feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit(X_train).transform(X_train)\n",
    "X_test_scaled = scaler.fit(X_test).transform(X_test)\n",
    "\n",
    "mlp = MLPClassifier(activation='logistic',solver='lbfgs',random_state=42, hidden_layer_sizes=(3))  \n",
    "\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Accuracy on the training subset: {:.3f}'.format(mlp.score(X_train_scaled, y_train)))\n",
    "print('Accuracy on the test subset: {:.3f}'.format(mlp.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical Recognition of Handwritten Digits Data Set\n",
    "\n",
    "* Can we build a neural network to classify handwritten digits?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](https://shapeofdata.files.wordpress.com/2013/12/digits.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data files train.csv and test.csv contain gray-scale images of hand-drawn digits, from zero through nine.\n",
    "\n",
    "* Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.\n",
    "\n",
    "* The training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n",
    "\n",
    "* Each pixel column in the training set has a name like pixelx, where x is an integer between 0 and 783, inclusive. To locate this pixel on the image, suppose that we have decomposed x as x = i * 28 + j, where i and j are integers between 0 and 27, inclusive. Then pixelx is located on row i and column j of a 28 x 28 matrix, (indexing by zero).\n",
    "\n",
    "* Read more on [kaggle](https://www.kaggle.com/c/digit-recognizer/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partner-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits = pd.read_csv('../../../datasets/digit_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "digits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How many features do we have?\n",
    "* How do we go about choosing the number of perceptrons to have in one hidden layer?\n",
    "\n",
    "Let's try using two perceptrons for visualization purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Time it\n",
    "now = time.time()\n",
    "\n",
    "# Create train, test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.drop('label',axis=1), digits.label, random_state=0)\n",
    "\n",
    "# Let's set a hidden_layer param\n",
    "hidden_layers_neurons = (10)\n",
    "\n",
    "# Scale\n",
    "#scaler = StandardScaler()\n",
    "#X_train_scaled = scaler.fit(X_train).transform(X_train)\n",
    "#X_test_scaled = scaler.fit(X_test).transform(X_test)\n",
    "X_train_scaled = X_train / 255.0\n",
    "X_test_scaled = X_test / 255.0\n",
    "\n",
    "# Instantiate a Multilayer Perceptron Classifier\n",
    "mlp = MLPClassifier(activation='logistic', max_iter=500, random_state=42, hidden_layer_sizes=hidden_layers_neurons)  \n",
    "\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "print('accuracy on training set is ' + str(mlp.score(X_train_scaled, y_train)))\n",
    "print('accuracy on test set is ' + str(mlp.score(X_test_scaled, y_test)))\n",
    "\n",
    "current = time.time()\n",
    "print('time difference is ' + str(current - now))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That took a long time! We will try to address the processing issue later. Let's see what our coefficients in our hidden layer look like and see if they separate the data well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,5)\n",
    "\n",
    "# use global min / max to ensure all weights are shown on the same scale\n",
    "\n",
    "vmin, vmax = mlp.coefs_[0].min(), mlp.coefs_[0].max()\n",
    "for coef, ax in zip(mlp.coefs_[0].T, axes.ravel()):\n",
    "    ax.matshow(coef.reshape(28, 28), cmap=plt.cm.gray, vmin=.5 * vmin,\n",
    "               vmax=.5 * vmax)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may not have the luxury to set the iteration to a very high number due to processing limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
